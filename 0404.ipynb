{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7+e5GrbZmOiMTI8NQAZNN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21700185-kimtaehong/Int_AI_sample/blob/main/0404.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-8L0hnaCPwRx"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "encoding_dim = 32\n",
        "input_img = Input(shape=(784,)) #784 = 28x28\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "encoder = Model(input_img, encoded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#need to re-define input layer for decoder input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoded = Dense(784, activation='sigmoid')(encoded_input)\n",
        "decoder = Model(encoded_input, decoded)\n",
        "\n",
        "outputs = decoder(encoder(input_img))\n",
        "autoencoder = Model(input_img, outputs)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "eGldiW7xQDSh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# float32 / 255 : 값을 0~1로 만들기\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n"
      ],
      "metadata": {
        "id": "Miv65Nm_QH0x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train, x_train,epochs=50,batch_size=256,shuffle=True,validation_data=(x_test, x_test))\n",
        "\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_CQHR0gRELg",
        "outputId": "e0b25fbc-f714-4b7d-e21d-3ca9f98c7cdc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 2s 4ms/step - loss: 0.2764 - val_loss: 0.1894\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1706 - val_loss: 0.1542\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1446 - val_loss: 0.1336\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1282 - val_loss: 0.1207\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1176 - val_loss: 0.1122\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1104 - val_loss: 0.1062\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1055 - val_loss: 0.1022\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1020 - val_loss: 0.0992\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0994 - val_loss: 0.0970\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.0954\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.0944\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0954 - val_loss: 0.0937\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0948 - val_loss: 0.0933\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0944 - val_loss: 0.0929\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0942 - val_loss: 0.0928\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0940 - val_loss: 0.0926\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0938 - val_loss: 0.0925\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0937 - val_loss: 0.0923\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0933 - val_loss: 0.0921\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.0920\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0930 - val_loss: 0.0917\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "313/313 [==============================] - 0s 1ms/step\n",
            "313/313 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10 # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_test[i].reshape(28, 28))\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  \n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "rsvW0rdUR24f",
        "outputId": "8ebf5c85-92ae-4bc7-a6a6-5db340b954fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABiEAAAE/CAYAAAAg+mBzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNwUlEQVR4nO3dabRdVZU/7B1agYSQBEIITQg9GATppC9A/oIISN+q2INC2aA0KlpKI0NRFFFAqhAFFUEFRMAUIEorFiCN9BKEEAIhkIaEJHTJ+6necq859W5Ozr73JnmeMfgw51jn3JV71l17n7M5+zdg3rx58yoAAAAAAIAuW6yvJwAAAAAAACycXIQAAAAAAABa4SIEAAAAAADQChchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBUuQgAAAAAAAK1wEQIAAAAAAGjFEk0GzZ07t5o4cWI1aNCgasCAAW3PiX5s3rx51YwZM6qRI0dWiy3W7jUs647/1VvrzprjH1l39DbHWPqCvY7eZq+jL9jr6AvWHb3NMZa+0HTdNboIMXHixGr11Vfv2uRY8D399NPVaqut1urPsO4otb3urDky1h29zTGWvmCvo7fZ6+gL9jr6gnVHb3OMpS/0tO4aXRYbNGhQ1ybEwqE31oR1R6ntNWHNkbHu6G2OsfQFex29zV5HX7DX0ResO3qbYyx9oac10egihK/VUOqNNWHdUWp7TVhzZKw7eptjLH3BXkdvs9fRF+x19AXrjt7mGEtf6GlNCKYGAAAAAABa4SIEAAAAAADQChchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBUuQgAAAAAAAK1wEQIAAAAAAGiFixAAAAAAAEArXIQAAAAAAABa4SIEAAAAAADQiiX6egKwsPr85z8fessss0zove1tb6vVBxxwQKPnP/fcc2v1n/70pzDm4osvbvRcAAAAAABt8E0IAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCsEU0MXXHrppaHXNGC6NHfu3EbjjjzyyFq96667hjE33XRT6I0fP76jeUFpvfXWC71HHnkk9D796U+H3tlnn93KnOi/lltuuVp9xhlnhDHlvlZVVXX33XfX6gMPPDCMeeqpp+ZzdgAAwKJqyJAhobfGGmt09FzZe5PPfvaztfqBBx4IYx577LHQu++++zqaA/RHvgkBAAAAAAC0wkUIAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIVgauhAGUTdaQh1VcUg3//+7/8OY9Zaa63Q22uvvWr12muvHcYcfvjhoXf66ae/2SlC6u1vf3voZcHqEyZM6I3p0M+tssoqtfpjH/tYGJOtn80337xW77nnnmHMD37wg/mcHQuazTbbLPQuv/zy0FtzzTV7YTb/2rve9a5a/fDDD4cxTz/9dG9NhwVEeZ5XVVV11VVXhd4xxxwTeuedd16tfuONN7o3MVozfPjw0LvssstC7/bbbw+9888/v1Y/+eSTXZtXNw0ePDj0dtxxx1o9duzYMOa1115rbU7Awu8973lPrd57773DmJ122in01llnnY5+XhYwPWrUqFq99NJLN3quxRdfvKM5QH/kmxAAAAAAAEArXIQAAAAAAABa4SIEAAAAAADQCpkQ0IMtttgi9Pbdd98eH/fggw+GXnbvwRdeeKFWz5w5M4xZaqmlQu+OO+6o1ZtsskkYM2zYsB7nCZ3adNNNQ+/ll18OvSuuuKIXZkN/stJKK4XeT37ykz6YCQur3XbbLfSa3lu3t5X39v/whz8cxhxyyCG9NR36qfKc7Zxzzmn0uO9///uh96Mf/ahWz549u/OJ0ZohQ4bU6uy9Q5ahMGnSpNDrjxkQ2dzvvvvu0CvPGcosqKqqqscff7x7E+NNW3755UOvzBkcM2ZMGLPrrruGnnwP5keZg3n00UeHMVnu3DLLLFOrBwwY0N2JFdZbb71Wnx8WVL4JAQAAAAAAtMJFCAAAAAAAoBUuQgAAAAAAAK1wEQIAAAAAAGhFvw2mPuCAA0IvC5iZOHFirZ4zZ04Y87Of/Sz0nnvuudATeEVmlVVWCb0yyCgLkstCM5999tmO5vC5z30u9DbaaKMeH3fNNdd09PMgUwbOHXPMMWHMxRdf3FvToZ/41Kc+FXr77LNP6G211VZd+Xk77rhj6C22WPx/Ku67777Qu/nmm7syB3rXEkvE09U99tijD2bSmTKI9dhjjw1jlltuudB7+eWXW5sT/U+5t6222mqNHnfJJZeEXvZ+iL614oorht6ll15aq4cOHRrGZAHl//7v/969ibXopJNOCr3Ro0eH3pFHHlmrvSfvW4cffnjonXbaaaG3+uqr9/hcWaD1iy++2NnEoIrHxk9/+tN9NJP/88gjj4Re9vkQC4911lkn9LLj/L777lurd9pppzBm7ty5oXfeeeeF3m233VarF9RjpW9CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFrRb4Opv/nNb4bemmuu2dFzlWFXVVVVM2bMCL3+GB4zYcKE0Mt+N3fddVdvTGeR9Nvf/jb0yiCabD1NmTKla3M45JBDQm/JJZfs2vNDExtssEGtzoJUy5BFFn7f+c53Qi8L2OqW/fbbr1HvqaeeCr2DDz64VpeBwfRPO++8c+hts802oZedH/UHQ4YMqdUbbbRRGLPsssuGnmDqhdfSSy8del/60pc6eq6LL7449ObNm9fRc9GezTbbLPSygMrSySef3MJs2vHWt761Vn/uc58LY6644orQc+7Yd8qQ36qqqu9+97uhN2zYsNBrss+cffbZoXfMMcfU6m6+Z6Z/KgN7szDpMnS3qqpq7NixoffKK6/U6unTp4cx2flT+b71uuuuC2MeeOCB0Pvzn/8cevfcc0+tnj17dqM5sGAYM2ZM6JX7VvbeMwum7tQ73vGO0Hv99ddr9aOPPhrG3HrrraFX/r29+uqr8zm7+eObEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANCKfpsJ8bGPfSz03va2t4Xeww8/XKs33HDDMKbpPTi33nrrWv3000+HMauvvnroNVHev6uqqmry5Mmht8oqq/T4XOPHjw89mRC9K7vXeLccd9xxobfeeuv1+LjsfoVZDzp1/PHH1+rs78BetHC79tprQ2+xxdr9/xlefPHFWj1z5swwZtSoUaE3evTo0Puf//mfWr344ovP5+xoQ3kv1ksuuSSMGTduXOh9/etfb21O8+O9731vX0+BfmbjjTcOvc0337zHx2XvJ373u991ZU50z/Dhw0Nv//337/FxH/nIR0Ive7/YH5T5D1VVVTfccEOPj8syIbJsPXrH5z//+dAbOnRo156/zOKqqqrafffda/Vpp50WxmRZEn19H3OayTIDy/yFTTbZJIzZd999Gz3/HXfcUauzz/qefPLJ0FtjjTVqdZa92mamHX0v+zz56KOPDr1s31p++eV7fP5nnnkm9G655ZZa/fe//z2MKT9jqao8t3Crrbaq1dlevccee4TefffdV6vPO++8MKY3+SYEAAAAAADQChchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBX9Npj697//faNeaezYsY2ef8iQIaG36aab1uosDGTLLbds9PylOXPmhN5jjz0WemXQdhY2koUxsuDac889a/XJJ58cxiy11FKh9/zzz9fqL3zhC2HMrFmz5nN2LKrWXHPN0Ntiiy1qdbaHvfzyy21NiT7wb//2b7V6/fXXD2OyELdOg92yoKwyzG769OlhzC677BJ6X/rSl3r8eZ/4xCdC79xzz+3xcbTrpJNOqtVZyGEZbFlVeWh5b8vO28q/I8GHNAkpzpT7If3Tt7/97dB73/veF3rle81f/vKXrc2p23bYYYfQW3nllWv1j3/84zDmpz/9aVtTooFRo0bV6g996EONHnf//feH3qRJk2r1rrvu2ui5Bg8eXKuzcOyf/exnoffcc881en56T/YZxc9//vPQK4Oov/71r4cxTYLtM1kIdWb8+PEdPT8Lrh/+8Ie1Ogs/X3HFFRs9V/lZ9F//+tcw5otf/GLoZZ8Dl7bddtvQy96j/uhHP6rV5efXVRX35aqqqh/84Ae1+te//nUYM3ny5J6m2TW+CQEAAAAAALTCRQgAAAAAAKAVLkIAAAAAAACtcBECAAAAAABoRb8Npm7b1KlTQ+8Pf/hDj49rEo7dVBZKVwZmZ4Enl156adfmQN8rw36zgKdMuQ5uuummrs0JyiDVTG8GGNG+LIz8F7/4Ra1uGt6Veeqpp2p1For1ta99LfRmzZr1pp+7qqrq4x//eOittNJKtfqb3/xmGPOWt7wl9L7//e/X6tdee63HOdHMAQccEHp77LFHrX788cfDmLvuuqu1Oc2PLBC9DKL+4x//GMZMmzatpRnRH+244449jnn11VdDL1tf9D/z5s0LvSyQfuLEibU6e8172zLLLBN6WdjmJz/5ydAr/90f/vCHuzcxuqIMMh00aFAYc8stt4Re9r6gPF869NBDw5hs7ay99tq1esSIEWHMb37zm9B797vfHXpTpkwJPdozcODAWv2FL3whjNlzzz1D74UXXqjV3/rWt8KYJuf7UFX5e7Xjjz8+9D760Y/W6gEDBoQx2ecZ5557buidccYZtfrll1/ucZ5NDRs2LPQWX3zx0PvqV79aq8eOHRvGjBo1qmvzaotvQgAAAAAAAK1wEQIAAAAAAGiFixAAAAAAAEArXIQAAAAAAABascgGU/e24cOHh94555wTeostVr8udPLJJ4cxApgWXFdeeWXovetd7+rxcRdddFHonXTSSd2YEqQ23njjHsdkob4suJZYIp4SdBpEfdNNN4XeIYccUqvLkLr5kQVTn3766aF35pln1upll102jMnW9VVXXVWrx40b92anyD9x4IEHhl75umTnS/1BFuZ++OGHh94bb7xRq0899dQwRtj5wmvbbbdt1CtloYf33ntvN6ZEP/Ge97ynVl933XVhTBZan4VmdqoMHN5pp53CmK233rrRc/3qV7/qxpRo0dJLL12rsxD173znO42ea86cObX6wgsvDGOyY/xaa63V43NnIcX9Ibh9UbfPPvvU6hNPPDGMGT9+fOjtsMMOtXr69OldnReLluw4ddxxx4VeGUT9zDPPhDH7779/6P3P//xP55MrlAHTq6++ehiTfdZ37bXXht6QIUN6/HlZ+PbFF19cq7Pzit7kmxAAAAAAAEArXIQAAAAAAABa4SIEAAAAAADQCpkQveToo48OvZVWWin0pk6dWqsfffTR1uZEu1ZZZZXQy+4BXN6bM7tPenb/6JkzZ87H7OD/ZPf6/dCHPhR699xzT62+/vrrW5sTC4677ror9D784Q+HXjczIJoocxyqKt6vf8stt+yt6VBV1eDBg0Ovyb3Gu3n/8276+Mc/HnpZjsrDDz9cq//whz+0Nif6n073mf667unZWWedFXo777xz6I0cObJW77jjjmFMdn/nvffeez5m96+fP8sIyDzxxBOh98UvfrErc6I9hx56aI9jyqySqspzDZvYYostOnrcHXfcEXre+/a9JnlG5fvFqqqqCRMmtDEdFlFlzkJVxfy1zOuvvx5673jHO0LvgAMOCL0NNtigx+efPXt26G244Yb/sq6q/D3yyiuv3OPPy0yaNCn0ys8S+zqHzjchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBUuQgAAAAAAAK0QTN2C7bbbLvROPPHERo/dZ599avUDDzzQjSnRB37961+H3rBhw3p83E9/+tPQGzduXFfmBJldd9019IYOHRp6Y8eOrdVz5sxpbU70D4st1vP/q5AFevUHWZhn+e9p8u+rqqr66le/Wqvf//73dzyvRdnSSy8dequuumroXXLJJb0xnfm29tprNxrnXG7R1jSYddq0abVaMPWC6+677w69t73tbaG36aab1urdd989jDnuuONCb/LkyaH3k5/85E3M8P9cfPHFtfq+++5r9Ljbb7899Lxf6f/K42sWcr7llluGXhbKuvHGG9fqfffdN4wZMmRI6JV7XTbmYx/7WOiVa7Wqquqhhx4KPdqTBfaWsn3sP/7jP2r1b37zmzDm3nvv7XheLFpuvPHG0PvDH/4QeuVnHGussUYY873vfS/05s2b1+McsiDsLDC7iaYh1HPnzq3VV1xxRRjzqU99KvSeffbZjubVFt+EAAAAAAAAWuEiBAAAAAAA0AoXIQAAAAAAgFa4CAEAAAAAALRCMHUL9thjj9BbcsklQ+/3v/996P3pT39qZU60Kwv12myzzRo99o9//GOtLoOboG2bbLJJ6GWBTL/61a96Yzr0kaOOOir0ygCsBclee+0Vem9/+9trdfbvy3plMDWdmTFjRuhlQYRlgOvQoUPDmClTpnRtXk0MHz489JoENFZVVd16663dng792Pbbb1+rDzvssEaPmz59eq2eMGFC1+ZE35s6dWrolUGaWbDmCSec0Nqcqqqq1lprrVo9YMCAMCbbpz//+c+3NSVadMMNN9Tqct+pqhg4XVV5AHST8Nby51VVVR199NG1+uqrrw5j1l133dDLAlezc1fas9JKK9Xq7Jx56aWXDr2vfOUrtfqkk04KY84777zQu+OOO0KvDBd+/PHHw5gHH3ww9EpvfetbQy/7LM6xuP+ZPXt26O27776ht8IKK9TqE088MYzZbrvtQu/FF18MvfHjx9fqbJ1nn6lstdVWodep888/v1Z/8YtfDGOmTZvWtZ/XFt+EAAAAAAAAWuEiBAAAAAAA0AoXIQAAAAAAgFbIhOiCZZZZplbvvvvuYcyrr74aetm9/1977bXuTYzWDBs2rFZn92PLckAy5X1WZ86c2fG8oIkRI0bU6h122CGMefTRR0PviiuuaG1O9L0sQ6E/Ku9HW1VVtdFGG4Veti83MXny5NBzbO6O7B6u48aNC73999+/Vl9zzTVhzJlnntm1eY0ZMyb0yvukr7nmmmFMk/thV9WCna3Cm1eeIy62WLP/5+v6669vYzrwL5X3as/2tSyXIjtW0v+VeUoHHXRQGJNlwA0ePLjH5z777LNDL1s7c+bMqdWXX355GJPdu3233XYLvbXXXrtWZ+cUdM+3vvWtWn3sscd29DzZcfGTn/xko16bsn2tzO+sqqo65JBDemE2zK8yHyHbV7rpoosuCr0mmRBZZl72t/XjH/+4Vr/xxhvNJ9eP+CYEAAAAAADQChchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBWCqbvguOOOq9Vvf/vbw5ixY8eG3u23397anGjX5z73uVq95ZZbNnrclVdeGXpZQDm06YMf/GCtHj58eBjzu9/9rpdmA2/Ol770pdA7+uijO3quJ598MvSOOOKI0Bs/fnxHz0/PsmPggAEDavV73vOeMOaSSy7p2hxeeOGF0CvDWVdcccWOn78MkmPhdsABB/Q4pgxLrKqq+uEPf9jCbOD/HHjggaH3gQ98oFZnAZkvvvhia3Oib91www2hl+1hhx12WOiV+1gZcl5VMYQ6c8opp4TehhtuGHp777136JU/MzuHo3vKYN9LL700jPn5z38eekssUf/YcfXVVw9jsrDq3rbSSiuFXvb3cNJJJ9XqU089tbU50T8df/zxoddpYPlRRx0Vet18n9Pf9P1fOgAAAAAAsFByEQIAAAAAAGiFixAAAAAAAEArXIQAAAAAAABaIZj6TcrCEb/85S/X6pdeeimMOfnkk1ubE73v2GOP7ehxxxxzTOjNnDlzfqcDb8qoUaN6HDN16tRemAn07Nprr63V66+/ftee+6GHHgq9W2+9tWvPT88eeeSR0DvooINq9aabbhrGrLPOOl2bw69+9asex/zkJz8JvcMPP7zR88+ePftNz4kFw2qrrRZ6WYBracKECaF31113dWVO8M+8+93v7nHM1VdfHXp/+ctf2pgO/VQWVp31uiU7RmaBx1kw9c4771yrhw4dGsZMmTJlPmbHP3rjjTdqdXbcWm+99Xp8nne+852ht+SSS4beV7/61dDbcsste3z+bhowYEDobb755r06B/reRz/60VpdhpNXVQxgzzz44IOhd/nll3c+sQWQb0IAAAAAAACtcBECAAAAAABohYsQAAAAAABAK1yEAAAAAAAAWiGY+l8YNmxY6H3ve98LvcUXX7xWlyGaVVVVd9xxR/cmxgIrC8t67bXXuvLc06dPb/TcWejT4MGDe3z+FVZYIfQ6DeguQ62qqqpOOOGEWj1r1qyOnpue7bnnnj2O+e1vf9sLM6E/yYLXFlus5/9XoUnQZVVV1fnnn1+rR44c2ehx5Rzmzp3b6HFN7LXXXl17Ltpz7733Nuq16Yknnuj4sWPGjKnVDzzwwPxOh35i2223Db0m++aVV17ZwmzgX8uO1y+//HKt/va3v91b04F/6rLLLgu9LJj64IMPrtXHHHNMGHPyySd3b2J0xe9///tG4zbddNPQK4OpX3/99TDmwgsvDL3//M//rNWf+cxnwpjDDjus0bxYuG211VahVx4bBw4c2Oi5Zs6cWauPOuqoMOaVV155E7Nb8PkmBAAAAAAA0AoXIQAAAAAAgFa4CAEAAAAAALRCJsQ/KLMdxo4dG8aMHj069MaNG1erv/zlL3d3Yiw07r///tae+5e//GXoPfvss6G38sorh155P82+8Nxzz9Xq0047rY9msnDZfvvtQ2/EiBF9MBP6u3PPPTf0vvnNb/b4uKuvvjr0muQ2dJrtMD+ZEOedd17Hj2XRlmWmZL2MDIiFV5YfV3rhhRdC76yzzmpjOvD/y+47nb0HeP7552v1X/7yl9bmBE1l53rZOel73/veWv0f//EfYcwvfvGL0HvsscfmY3b0luuuuy70ys8IllgifqT5sY99LPTWWWedWr3TTjt1PK8JEyZ0/Fj6vywzcNCgQT0+rsxYqqqYZXPbbbd1PrGFhG9CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFohmPofrL322rV68803b/S4Y489tlaXQdUsfK699tpaXYZi9YUDDzywa8/1+uuvh16TMNirrroq9O66665GP/OWW25pNI43Z9999w29xRdfvFbfc889YczNN9/c2pzony6//PLQO+6442r1Siut1FvT+acmT54ceg8//HDoffzjHw+9Z599tpU5sfCbN29eox6Llt12263HMePHjw+96dOntzEd+P9lwdTZnnXNNdf0+FxZIOeQIUNCL1vr0C333ntv6H3lK1+p1WeccUYY8/Wvfz303v/+99fq2bNnz9/kaEV2fn/ZZZfV6oMOOqjRc+288849jnnjjTdCL9sjTzzxxEY/k/4vO74df/zxHT3Xz372s9D74x//2NFzLcx8EwIAAAAAAGiFixAAAAAAAEArXIQAAAAAAABa4SIEAAAAAADQikU2mHrUqFGhd9111/X4uDKks6qq6uqrr+7KnFhw7LfffrU6C69ZcsklO3rut771raF38MEHd/RcP/rRj0LvySef7PFxv/71r0PvkUce6WgO9J5ll1029PbYY48eH/erX/0q9LJgLhZuTz31VOgdcsghtXqfffYJYz796U+3NaXUaaedFno/+MEPenUOLHre8pa3NBon3HLhlZ3Xrb322j0+bs6cOaH32muvdWVOML/K873DDz88jPnsZz8beg8++GDoHXHEEd2bGDRw0UUX1eojjzwyjCnft1dVVZ188sm1+v777+/uxOiK7JzqM5/5TK0eOHBgGLPFFluE3vDhw2t19pnIxRdfHHpf/epX//UkWWBka+Whhx4KvSaf42V7Rrk2yfkmBAAAAAAA0AoXIQAAAAAAgFa4CAEAAAAAALRikc2E+PjHPx56a6yxRo+Pu+mmm0Jv3rx5XZkTC65vfvObrT7/YYcd1urzs3DI7jE9derU0Lvqqqtq9VlnndXanFiw3Xzzzf+yrqo8Tyk7xu611161ulyHVVVV559/fugNGDCgVmf37oS2fehDHwq9adOmhd4pp5zSC7OhL8ydOzf07rrrrtAbM2ZMrX788cdbmxPMr49+9KO1+iMf+UgYc8EFF4SevY7+YPLkybV61113DWOye/+fcMIJtTrLQqF/mjRpUq0u319UVVW9//3vD72tt966Vn/ta18LY55//vn5nB392S677BJ6q622Wug1+Xw3y0rKMsCIfBMCAAAAAABohYsQAAAAAABAK1yEAAAAAAAAWuEiBAAAAAAA0IpFIph6++23D71///d/74OZALQnC6bedttt+2AmLErGjh3bqAcLsjvvvDP0zjzzzND7wx/+0BvToQ+88cYbofelL30p9MpAw7vvvru1OcE/c8wxx4TeySefHHo333xzrT733HPDmKlTp4beq6++Oh+zg3aMHz8+9G644YbQ23vvvWv1RhttFMY89NBD3ZsYveriiy9u1GPRcsopp4RekxDqqqqqM844o1Y73++cb0IAAAAAAACtcBECAAAAAABohYsQAAAAAABAK1yEAAAAAAAAWrFIBFPvsMMOoTdw4MAeHzdu3LjQmzlzZlfmBADAgmGvvfbq6ynQD02cODH0PvzhD/fBTKDu1ltvDb1ddtmlD2YCfeuAAw4Ivfvuu69Wr7POOmGMYGpYuAwdOjT0BgwYEHrPP/986H33u99tY0qLJN+EAAAAAAAAWuEiBAAAAAAA0AoXIQAAAAAAgFa4CAEAAAAAALRikQimbqoMKHrnO98ZxkyZMqW3pgMAAABAB1566aXQGz16dB/MBOhLZ555ZqPeKaecEnrPPvtsK3NaFPkmBAAAAAAA0AoXIQAAAAAAgFa4CAEAAAAAALRikciEOP300xv1AAAAAABYOHznO99p1KNdvgkBAAAAAAC0wkUIAAAAAACgFS5CAAAAAAAArWh0EWLevHltz4MFTG+sCeuOUttrwpojY93R2xxj6Qv2OnqbvY6+YK+jL1h39DbHWPpCT2ui0UWIGTNmdGUyLDx6Y01Yd5TaXhPWHBnrjt7mGEtfsNfR2+x19AV7HX3BuqO3OcbSF3paEwPmNbh0NXfu3GrixInVoEGDqgEDBnRtcix45s2bV82YMaMaOXJktdhi7d7Ny7rjf/XWurPm+EfWHb3NMZa+YK+jt9nr6Av2OvqCdUdvc4ylLzRdd40uQgAAAAAAALxZgqkBAAAAAIBWuAgBAAAAAAC0wkUIAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWuAgBAAAAAAC0wkUIAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWuAgBAAAAAAC0wkUIAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWuAgBAAAAAAC0wkUIAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWLNFk0Ny5c6uJEydWgwYNqgYMGND2nOjH5s2bV82YMaMaOXJktdhi7V7Dsu74X7217qw5/pF1R29zjKUv2OvobfY6+oK9jr5g3dHbHGPpC03XXaOLEBMnTqxWX331rk2OBd/TTz9drbbaaq3+DOuOUtvrzpojY93R2xxj6Qv2OnqbvY6+YK+jL1h39DbHWPpCT+uu0WWxQYMGdW1CLBx6Y01Yd5TaXhPWHBnrjt7mGEtfsNfR2+x19AV7HX3BuqO3OcbSF3paE40uQvhaDaXeWBPWHaW214Q1R8a6o7c5xtIX7HX0NnsdfcFeR1+w7uhtjrH0hZ7WhGBqAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWuAgBAAAAAAC0wkUIAAAAAACgFS5CAAAAAAAArViirycA/d1SSy0VeiNHjqzVn/vc58KYvffeO/SWXXbZ0Js3b16tnj59ehgzYcKE0Lvzzjtr9c033xzG3HfffaE3efLk0HvllVf+5ZygqQEDBjTqlbI1Zx0uXMp1sPjii/c4pqqq6o033qjV1goAAKXsPNI5It222GI9/7/c3q9AzjchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBUuQgAAAAAAAK0QTA3/IAsZWn755UPv7W9/e63eaaedwpjhw4eH3tJLLx16ZYDWSiutFMass846obfddtvV6n333TeMOeKII0Jv0qRJodcmAWH9T5Og6OxvYYUVVqjVb3vb28KYwYMHh97jjz8eehMnTqzVM2fODGNef/310CvXjrXU97L1tNxyy4XeDjvsUKv32GOPMGa11VYLvYcffrhW//znPw9jHnroodCbO3dunCwLpGyNZcHmTYICs32lm2slm2vZa3pctIYXLeX6fctb3hLGLLnkkqE3Z86c0HvttddqtbXUP5V7wRJLxLfm2X7xxhtvNOrBwq78+8jODbJe+feS/f14j9GzbH/KzsWavH/r7d93Ns9ll1029EaNGhV6++23X60eOXJkGHPjjTeG3tVXX12rZ8+e3eM8YWHjmxAAAAAAAEArXIQAAAAAAABa4SIEAAAAAADQChchAAAAAACAVgimhn+QhStlwdTbbLNNrc4Cp7OgwCwQs+y9+uqrPc6zquJcs2DW5557rtEc2gyCyp5bWHXf6vR3XYZ1bbbZZmHMGmusEXpZkGYZkJ6FZvaH0DI6k+2Jm2yySa3eaaedwphVVlkl9MaMGVOr77jjjjCmDK9mwZEdD8pw1uw4PGjQoNDLAtGnTp1aq1988cUwJjvuNtlrsrln+105rywMcdasWaH3yiuv1GrhwguPbO0MHDiwVh900EFhzFZbbRV6N910U+j99re/rdUzZswIYxxPe1cWjjtkyJBaveaaa4YxM2fODL1p06b12Gu6r3VzHTQJVy/XeVXF/S/bD+1/fSvbs8pe07XUzTXX5Lmyc9Jy7tm/L/vby95HL0rK31N2PlOew2Wy161pOHjZy+YwePDg0Hvf+95Xqw877LAwZvTo0aGXnW+W/8Zs7mV4dVXFz5BOO+20MGbKlCmh53jNwsQ3IQAAAAAAgFa4CAEAAAAAALTCRQgAAAAAAKAV/TYToul9dpdZZpland1vM7sn5uzZs0Mvu5cbi5Zs/QwfPjz0yvuS/ulPfwpjxo8fH3rlPXqrqqr+9re/9Tiv9ddfP/S+9KUv1ersfoUjR44MvSeffLLHn9dN2d9y+XdbVZ1nY9CO7N6T5d/HqquuGsZk92SfOHFi6E2fPr1WL+r3WF2QZX/jq6++eugdfPDBtXq99dYLY7I9uFxTRx99dBhz9913h1627txTdcFQ3mt3xIgRYUx5X92qys/t/vznP9fqLBOiU03PVct7E2f75PPPPx96r732Wq2Wk9MdTe5tnmn79/+2t72tVn/ta18LY8oMgarK99Lf/e53tdo66V3ZsWyDDTYIvc985jO1OjuvevTRR0PvZz/7WeiVuR/ZHJpomh3X5Px+u+22C2N22GGH0Csz7K688sowxjG992RrJ8v3KPej7N782TG3PFZ3M+8je65srQ4bNqyjOZTvX6pq0VqH5b+1aY5Dk2NsNiZbU+VafNe73hXGnHHGGaFX5hZmz92pLAejXGNVFXMpst/fWWedFXrPPPNM6C1K625B1iRHpelaLI/PC+oa8E0IAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCv6TTD10ksvXauzMOAxY8aE3jve8Y5anYXzTp48OfTuvffe0HviiSdq9csvvxzGZIGDyy67bK3OAmaysMQswKYM9MoCeiZMmBB6L730Uq3uZsDTwqwMgSnDI6sqD5B88MEHa/Vll10Wxjz00EOhN2fOnDc7xaqq8jC2DTfcsFZnfzMHHXRQ6JUhnVXV7nppGphThkwJpq5rEuiV6WZg0YorrlirV1pppTAmW/fl30tVeX0XJtke+YMf/CD0Nt5441rdaWjm5ptvHnonnXRS6H37298OvfI471jZPy2//PK1Ogsd3H777UMvO76V519l2HNVdb5PZo/L1tQKK6xQq9dee+0w5pVXXgm9adOmdTQv5l/TY26nayfb/w477LBanQWyZ/PK1lz2Hob2lO8nskDST37yk6G3++671+rsdfvv//7v0Pvb3/4WeuVel63NJuGX83PeWO512fuQddddN/Qef/zxWn3PPfeEMc8//3zoZfs5b062F62++uqhd8wxx4TerrvuWquzvei6664LvfPPP79WP/nkk2FMp+dn2frNjq+zZs2q1Vnwtvcqncleu3LvydZd9tlY9tleGXh/2mmnhTFlCHX2M7PP7LLg8ZkzZ4Ze+flf+VlmVeX705QpU2r1yJEjw5js95Ad+xfUUOL+pun5Xrl+Bg4cGMbssMMOoXfsscfW6vXXXz+Mydbiiy++GHo/+clPavU111wTxmSfFZd7YNP3L23xTQgAAAAAAKAVLkIAAAAAAACtcBECAAAAAABohYsQAAAAAABAK1oPps6CPrJw5zLw9K1vfWsYs8suu4TeVlttVavLQKyqyoM3dtxxx9ArA0Gy0NUsqGmppZaq1VmQYBm4VVV5ONiQIUNq9aRJk8KYLGzztttuq9XCNqPs912GCGUhSVm4y6OPPlqrn3vuuTDm9ddff7NT/Kc++tGPht7o0aN7fNxGG20Uetm/sbeD3bKg9k6DlxdVbQdUZQFb22yzTa3O9sgshHrGjBldmxd9K9s/skC48tj8zx5bahKUtcwyy4Qx++23X+iV67Wqquqss86q1ZdddlkYI9C1d2V7WRncvM8++4QxWSDcRRddFHovvPBCrW47yC/796y88sq1evjw4WFMeS5ZVXGuQgi7I/s9lq9b28fY5ZZbLvTe+c531ursvDULL7zkkktCT6Bqe7K1UR7fslDUDTbYIPTKANInnngijPnlL38Zell4ahPdfH+Y/R7Kf+PGG28cxmQhwX/5y19q9cMPPxzGCKHujnJfyd5PXnHFFaGXrd/yubLXaPDgwaFXnseV52ZV1XlYdbZPZ/thGRCcPc6a655yj8yCwLPzoEz5WdvUqVPDmOyzhnL9ZOeMp556auhl7wvKzxxHjRoVxmTvV8o9P1vnEydODD2f7XWm3KOyNZadk6+77rqht/vuu9fqXXfdNYzJ9tMyxDw7dmafG2afa59wwgm1+sADDwxjfv3rX4fe1VdfXaufeuqpMGbOnDmh1xbfhAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWtJ4JkcnuuVfeB+ull14KY7J7V6255pq1OruXVZarMGvWrNAr78+a5T9keRYzZ86s1XfeeWcY88wzz4TebrvtFnrlPURXWWWVMObtb3976N1+++2hR112L71yvWT3YyvvGVlV8Z682T16OzV06NDQ+9SnPhV65T3usnsffve73w29/nCf4GwPcK/rN2d+MjTK33V23+lsHe688861uryvZVW5j+XCplxn73nPe8KYj3/846GXrY1Sti7K42nWy567vN9mVVXV+uuvH3rf+ta3anWWP3X66aeH3osvvhh6dEd2XlVmQKy33nphzGOPPRZ6WSZNk3s6Z/tp2WuSI1BVMdurqqrqve99b63O1uvdd98deo6LvadJJkSnsmNsmXtSVVU1YsSIWp29/tk56dixY0PP2umObB1kr2d5XFp11VXDmOWXX77H5/rb3/4Wxjz//PM9zrOpbq6LMuumqqrqM5/5TK3OssNuueWW0LvqqqtqdZavSHeU9xnPsrGyc6Psb6E8j8sy4LLPYTbZZJNanZ1HnnPOOaGXfZ7S5D14dr7ZH94PL6yytVJmQGT35s/WT/b6/ulPf6rVH/zgB8OYrbfeOvTKc/nrr78+jMkyazJlTkT2/jc7VpS97LMn75s7k70/LLNsPvGJT4QxW265Zehln4OUeZnZ69skf+bee+8NY7Jckx122CH0ys+GN9100zAm+wy7zCc5++yzw5hs7bd1LumbEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWtB5M3SSEuqpiYEcZ9lJVVTVhwoTQu+GGG2p1FmqZBfZmgTkrrrhirc4CbTJ33HFHrc5Ck4YPHx56m2++eeits846tXrxxRcPY7KwLgF0nSl/b1mAZbZWuvn7Lp//hz/8YRhThqZXVZzrZz/72TDm2muvDT1hR4uWJms122c23njj0Ntss81q9d///vcwJgtWYsE1cuTIWn3++eeHMWVQ1z9Thss99NBDYUx5TK+qGDSWBf+Wa7Oq4tyrKgbj7bvvvmHMbbfdFnplaGaTIESaGTVqVOjtsssutTo7b7zuuutCLzv/6nQPLGWveRZKt+2224beHnvsUauzoM7svNfxuveU66Sb53lZ+Ppee+0VeuW5Xrbmbr/99tDrZnBxqe1z4P4u+7c2CanPQqjL4PGqimGR2TlUN3/f2V7X5PmzgOkf/ehHoVe+t82Cts8888zQK0NdF6U11qbs9d57771rdRncWlX53322H/31r3+t1ZdeemkYM3jw4NDbf//9a/V+++0XxsyZMyf0vvOd74TeSy+9VKutnb637LLLhl55Tv7ss8+GMdnnMNnrWa7FcePGhTFlCHVVxeDd+Qknb3LO4ByuPdnettFGG4Ve+blatt9l5/LTp08PvTvvvLNW33LLLWHMn//859B75JFHanW5Z1VVPBeoqqr6xje+EXof+chHanUWxr3CCiuEXvZZdKk3z/d8EwIAAAAAAGiFixAAAAAAAEArXIQAAAAAAABa4SIEAAAAAADQitaDqTNNwqqzIJcytCob12mAWFXFwOfx48eHMVlgTjn37OdloSFZaFkZjJIFl9xzzz2hJySzPW0HXK211lq1escddwxjsr+HMvzrggsuaPQ4Fg7Za9t0rZb7X7Y/lcGwVVVVAwcOrNXZ/jRlypRGc+hUOXcBdN1ThjZXVVWdeuqptToLp8xkQcInnXRSrc5CLbO1WIa1ZtZdd93QO+KII0Jvt912q9WrrLJKGHPkkUeGXhmYPWPGjB7nRJS9vuVrUlUxoO3xxx8PYy6++OLQy4Isyz0iO/9rsp82Pbd7//vfH3orr7xyrc72zixc2P7We8rfdbYmmp5TlWss28PKsPKqiu8BZs+eHcZk+2b23qRTjrE9a7I2smDIQYMGhV4ZWp4F22fBvuV71sxSSy0VetlaLN9DrrrqqmHM97///dDbYostepzX17/+9TDmwQcf7HEOdEe2BtZee+1ane0f2d5z+umnh96FF17Y4xw+9rGPhV55TCz/DqqqqrbbbrvQO/vss0PPHtW3stdun3326fFxV1xxReh1+lpm+8fLL78ceuVat3YWHOW5SXY8/exnPxt6Y8aMqdXZe91srVx//fWh98UvfrFWZ595ZGuxybljtg9vvPHGoVf+vWXvabL3JpMnT67VWSh7b/49+CYEAAAAAADQChchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBV9EkzdxPyErjaRPVf5M7OAw06Dftdbb73QGzVqVOiVYSbXXnttGPPEE0+EnmCdBcPQoUNDrwx7ywJznnnmmdD7yle+UquzINimFl988Vrd9t8fb16bv/8sqHCHHXYIvXJ/uu6668KYLNypydyzYKWsZx22Jzsm7bnnnrU6e02yEK7zzjsv9M4888xane1Z5V5UVTFMK9ufxo8f32he73rXu2p1Ftq42Wabhd6QIUNqtWDqzmQBq5tssknozZo1q1ZfdtllYczEiRNDr8n+kI3pdF/Jgtq32mqr0CtD4u65554wJgurpvc0CSJvqgyYXnfddcOYDTfcsMfnmTBhQujdfvvtodfpe5NsP6cz5Wswc+bMMCYLnlx22WVrdRb2fMIJJ4TenXfeGXrLLLNMrS7XYVXlx91hw4bV6mOOOSaMGT16dOhlx9irrrqqVmfhnvPzfoU3JwsoLcPDsz0lCyK/4YYbQq98LbNj4ic+8YnQGzhwYK3O9jDvARYM2267beideOKJoVee91x55ZVdm0O2LrLg3ZI1tuAqw+2rKj9+lp+rZa95uSdWVX7syj4bLjX5PCN7r7v//vuH3pZbbtno+UvZ2i///rLjt2BqAAAAAABggeciBAAAAAAA0AoXIQAAAAAAgFb0m0yI8v5Wbd+Tqsn9tDq9x2p2/8Wjjjoq9LJ7/5f3OL7gggvCmOw+o+5f17ey13zEiBGhd+6554beNttsU6tnz54dxpx99tmhl+VElLJ1vvTSS4deed/YbA4sPMrXe6211gpjsvU7bty4Wn3NNdeEMdk9j5tomgnR6b5MXXav6He84x2hV+aFZL//v/3tb6H35S9/OfSarI1O7xWd3f/yscceC73yPpzZGsuOzWUmxNNPPx3GOA5H5TrLckfK+5FXVTwXuummm8KY7H6mbcrWSnn8rqo8Y6fMEPnP//zPMKbJ/YtZMCy55JK1+uCDDw5jyiyAqop75M9+9rMwJrt3cRNyl9pV7kdZ7sv9998feptvvnmtzt5PHHrooaH3/ve/P/ReeeWVWv3AAw+EMdl7hzLHJjsnzO5hna3Fc845p1Z3ek7Im5ed12Wv2yOPPFKry3P7qqqqP/3pT6GXnf+V+9g3vvGNMGbVVVeNky1k91rPsr6yf2Nvf4a0qCvPkb/+9a+HMWuvvXbolWulzLCpqjxXsFPZes3WDwuG8rXL3jtkOX+lbH/I9smDDjoo9Mp1na2x559/PvSmTJlSq/fbb78wZp999gm9Jv+e7Bj75z//OfTK84G+Pif0lwgAAAAAALTCRQgAAAAAAKAVLkIAAAAAAACtcBECAAAAAABoRb8Jpi51MwQjC9koQ+Oqqnshh6uttlro7bzzzqGXhRD+13/9V63OAj8Fs/a9ck2tv/76YcwvfvGL0MvGlYEyN954Yxhz0UUX9fi4TLbOs2DqWbNm1WqhXn2rm8FA2XOVQUfvfOc7exxTVVV1yy231OrnnnsujOnmPK3D9mThbBtvvHGP47LQ+u985zuhVwbx9oVsryv/PU2DubKwanpWhr0NHz48jMn2mvL8qNPA8m7KQhSPPPLIRo8tg7XvvvvuMMZ+147s7znTzWPXCiusUKt32223MCbbg8vwwssuuyyM6ebfQvZvtg47U/7eHnvssTDmC1/4Quh9+MMfrtXrrbdeGJMdy7Jg8wkTJtTqa665JozJ3utuvfXWtTpbm9m6+OMf/xh6Zcix9dR7mp5HT58+vVYPGjQojHnHO94ReptuumnolWGq2Xlk9rnFCy+8UKuzcOwyaL2qqmrMmDGhd8cdd9TqLOSa7inDeTfccMMwJtuzyoDybI1de+21odfpHpJ9BlL2suNptkdmPXtb35o2bVroZcfdVVZZpVZn+2R2PM0+u911111rdZPg6Ey2Npvu3+X78FtvvTWM+fKXvxx6ZWB2X69p34QAAAAAAABa4SIEAAAAAADQChchAAAAAACAVrgIAQAAAAAAtKLfBFN3KwijaQh1FjJZhvM2VYaSnHDCCWHMwIEDQ+/OO+8MvQsuuKBWNwkfpveVa+r0008PYzbYYIPQy9bnU089VauPP/74MKYMK2wqC53JAmOFnfedpqGZ3Xz+MoSuDCX8Z+6///5aPT/7Uzkva7B3NQlTraoY8Pfss8+GMWPHjg29bO/pdF5Nzg+yIM2999479LKwvFIZilxVVTVx4sQ3PSdiMHX2e8vWSvk6bb755mFMGa5ZVVU1derUHp8/WytLLBFPh8sg6kMPPTSM2WyzzUIv+zdeeumltToL3KQ7yj2k0z2lqWw9jRo1qlaPGDGi0RzGjx9fq8ug4W6zj3VP+bsswyOrKg+k/+tf/1qrs2NUtj9lr135PjY7lmXvf8vA4fXXXz+Myfbbb3zjG6GX/Ux6R7YmsuDdcs/af//9w5j99tsv9JZffvnQK/fX7LOU6667LvQuv/zyWj169OgwZrvttgu9r3zlK6F31lln1eos3NjnKZ3Jjm/l65LtWdnjys9OTj311DAmO4d7+OGHQ688t8wCy/fYY48en78M662qqnr66adD77777gu9yZMn12rvY9tV/n6ffPLJMOakk04KvV122aVWL7fccmFMdp5YBlpXVfy8pAxpr6o85Lpcr9nPy/aoSZMmhd63v/3tWn3JJZeEMdnnhuWxoK/P/3wTAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFqx0GVCNFXe57qqmt3DOrvHXXl/sOw+1C+//HLonXnmmaFX3quu099L2/fAXdSV9x7cfvvtw5hsrcycOTP0yvtMP/HEE2FMp69ddn9C66BvtZ0B0cTw4cNrdZZfku2HDz74YK2en/tflr+HbF1aq+0p709ZVfl9oEvZ/VOznJlO55BlODW5l+/GG28ceieeeGKPz5+tsWnTpoXeiy++2OMciMp9pMxAqqqq+vvf/x56G220Ua1+73vf2+OYqop7VFXFe5mvuuqqYUyW0VDeh/2YY44JY7J7ZGf3xC7v7e/ewQuP7Ji+zTbb1OosFy7be2688cZanb1XmZ950Z4m5yvZeVWZHZFlSXRTtqbKzKMs/+GXv/xl6GX7bZPfQ6dr0znhm9ckJyK7r3m2Z2Xva8v1esYZZ4Qx3/3ud3uc1z777BPGHHHEEaG34oorht4XvvCFWn3vvfeGMWXeTjYHouycvDx/yfaULHumtM4664TeT3/609DL1t3gwYNrdXYf/uz1Ld/DNM2wuf3220OvfI9R7qN0V5PcpQceeCD0uvnZRZkn8elPfzqM+dSnPhV6Q4YMqdXZucBjjz0WellO7E033VSrs7+/BWFv800IAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCv6TTB1t2RBHE1DZ0pZcNbQoUND79vf/natLkNLqqqqLr300tC77bbbQq9JOHYTC0IgyYKiDKesqqo67bTTanUZkPTPXHPNNaHXzcCcUtvroAyLWmaZZXocU1V5mFC59hflNdzNf3v2+y9DfIcNGxbGPP3006H33HPPdTSHbC8t5yVEvXdl+1oW7FaGy40YMSKMWWqppTqaQ7Y2s+NnuX7WXHPNMOYXv/hF6JVBYJlsjV144YWh13ZY6MKq3NezfeWSSy4JvR133LFWb7DBBmHMJptsEnpjxowJvTLYfObMmWHMLbfcEnpl6HR2nM/WcJPA9WxPtN+1I/u9dvN3nZ33HHjggbU6C/fM9pTf/e53tbrp+WC2nsqe9UVV5cG+73vf+2r1tGnTwphvfOMbodfN42K5l7b9d7swaBLw3SQA9Zxzzgljst91eSytqhgK/de//jWMKYOwqyruiePGjQtjXnjhhdDLArPL89TVV189jJkwYULodeszl4VZdgz6y1/+Uquz0PryHK6q4muXvQ9ZaaWVQi87xmbnWaXs9R00aFCtzt6/ZL2VV1459O66665a/YMf/KDRHOiObI9q+/ddvn+4+eabw5gjjzwy9Mp5ZZ+nnHDCCaF34403hl65Dy+ox0XfhAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWuAgBAAAAAAC0YqELpu6mLDDngx/8YOiVIZlZ8OJZZ50VerNmzep4bvSe9ddfP/S22WabWp2FU2ZBXFdeeWXolaFPTQIGs14WTNNpqGEW+JQF0u655561etVVVw1jbrrpptC7//77Q2/KlCm1Ovv9LQx6O0AoC8T8f//v/9XqLITrkUceCb0yrLDpv6VJMPWCGqy0oMrWRRa8Wx4HV1lllTAmCwi+4YYbQq/cj7I5rLvuuqFX7rdHH310GDN69OjQaxLa+Oijj4be9773vdCzPjtTvuZZkGkZclhVMThz5MiRYUx2bC5DB6uqqqZPn16rs+NPFhJXPtdBBx0UxmR/D9n5QHZspB1t/q1me8rw4cNDr1yb2eOyNXfPPffU6vkJpi7XoYDMvtfkmNRUk3WevY/Njm+rrbZarf7tb38bxjz77LNvYnb/WjZ3QertyN5Lle+3Lr/88jCmyfvVf9YrZeu+3I/uvffeMKYMva6qqjr00ENDr/w3ZgHa2d9COXdrLsqOG+V5c/Y6Zediyy+/fK3eaaedwpgPfOADobfhhhuG3rLLLht6pex8s1SGmldVfg633HLLhd72229fq88999wwxnF34VKuu1NOOSWMyT4vK9fB2LFjw5hbb7019LK9bGHZp3wTAgAAAAAAaIWLEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKwdT/oAxOWmuttcKYD33oQz0+Lgt4+tvf/hZ6C0uwyMIkCyMqw5erKg8oKmWv70YbbRR6Q4cO7fFxZfh5VcUwxCw0rgwfq6o8nGurrbaq1Z/4xCfCmCwYqgw0fuaZZ8KY7HfVJMD6HwPe582b1zigcVGWhb+tvPLKobfrrrv2+Lgbb7wx9F599dX5mF2d/a9vZa/ljBkzQq98nbIQ8+OOOy70Jk2a1OPzH3744WHMBz/4wdArQ4mzOWR7d7bGyj1qn332CWNeeuml0KM7sn08W4tTp06t1dlr8ve//z30srDzOXPm1OpXXnkljMnWSjnugQceCGO23nrr0MvWYnmcX3zxxcOYLECU/iU7Vq633nqhN3DgwFqdvbZXXHFF6HW692Trt+xlc3ccbk+TsPCmOn2dsvO/HXfcMfTK/ej3v/99GNP2OXj5b3TO37NyjWVrLvs9NllPTQN1y5+ZHduyn1fOKwsRvuWWW0LvqaeeCr111lmnVi+99NJhTBaUXJ6TZiGwi/o6zF67WbNm/cu6quI5XFXFtVIGXFdVVV133XWhd9ppp4Ve+T4221uzNVx+JtHpnlxV8X3O/DwXfSvbO1dYYYXQKwOlt9hiizAmWwcvv/xyrf7+978fxsycOTP0FuZzNH8tAAAAAABAK1yEAAAAAAAAWuEiBAAAAAAA0AqZEP9g2WWXrdUnn3xyGDNixIjQe/LJJ2v1+eefH8Zk9xmk/8nuCZdlKDS5R1t2X8yjjz469A499NBavcwyy4QxWa5Cec+58r7XVZXfh3j55ZcPvfJnZnPPlPfyzu6dmd2Hs7w/dlVV1Vve8pZa3fR+pPyf7D6ERxxxROiV99jP7sX6hz/8IfQ6vTdqk/vBLsz3PeyPsnu4XnDBBaF3xhln1OrsXrs77bRT6N1+++2hV+6vTbMdsn25lO0XWRbT/vvv3+MY+l65H2Svb7ZvZb1O963ycdn9+rPnzo675fybrGn6n+x1e+973xt65Xljti7PO++80Ovm/cfLvyHH2L6XvQblMS9bA03XRflcY8aMCWPK97pVFc/ln3jiiUY/r1NN8klkmCwYshymUvYZSJPXMnvcc889F3rlvduzz2rK9z1VVVUTJ06s1dOmTQtjZEJ072+ufK7s9c3OybNMiDXWWKNWjx49OozJPk9p+vlGKfuMpXyfk62VTvcx+1/vKnO8qqqqLrvsstArMyCy96zZe4Djjz++Vj/44INhzKL2+vomBAAAAAAA0AoXIQAAAAAAgFa4CAEAAAAAALTCRQgAAAAAAKAVi2wwdZPQ4N13373Rc51zzjm1ugw6YsGRhQr95je/Cb1DDjmkVq+33nphTBZonQUyDxs2rFY3DawsA2yyUJ1Owy+z30MWIDVu3Lhafemll4Yxv/jFL0JvypQpoTd9+vQ3M0USWej4AQccEHrl/vfiiy+GMdlr1KksbEloZt/Kft/Z3+pHP/rRWp0FXWZ7XdbrVDnXLCDu+uuvD72jjjoq9CZNmvQvn5v+qcke0m3lGi6P1VUVA12rKt9P77777lq9qIddLqiyoMvtttsu9Mq1ma2JrNepJn8L9rre1XTP6uZeUIYEH3nkkWHMcsstF3qvvPJKrc6CfbP3zVkAZyl7H5KFeZas154ttdRStTr7XWfv3d54441a3fR3na2B8mdma6Kbr2X2byzD1rP32uW/uaqq6qWXXqrV3of2vWytPPLII6F344031uqPfOQjYUz595E9f3YON3PmzND78Y9/HHq/+93vanU31779rz3lcbKqqurTn/506P3bv/1b6JXHrux1yj43/K//+q8eH7eo8U0IAAAAAACgFS5CAAAAAAAArXARAgAAAAAAaIWLEAAAAAAAQCsW2WDqTTbZJPSOOeaYWp0Fl9x3332hd9lll9VqYSMLruy1e+ihh0Jvl112qdV77rlnGHPwwQeHXhZgPWTIkFrdNNB1xowZtfqFF14IY7IA12xcGZCY/ZvLEOqqqqrbb7+9Vj///PNhTBb6lIXSCep8c7JwtpVWWin0sqCsadOm1eorrrgijJk9e3bnk2vA693/ZEGpe+21V62+6KKLwpgsmDU7fpZrtmlI57PPPlurP/CBD4Qx5V5UVTFsE/6ZbD8twy2zY/PEiRND749//GPoPfnkk7Xa/tf/ZWti5MiRobf00kuHXnnulb13yIJSu8l7kUXPsGHDavWYMWPCmCxcuAxw3XrrrcOYa665JvRmzZoVep2GpJc967dn5XFk4MCBYcxb3vKW0CtftyYB41XVLPi6m8e27OcNGjQo9Mr3Pln4euapp56q1U0C0+l92bn8D3/4w1qdHZuzYOFyvd5xxx09PndVVdVdd93V47zsWf1TuY+MGDEijHnf+94Xetmxsjxvu+6668KYQw89NPSc80d2WwAAAAAAoBUuQgAAAAAAAK1wEQIAAAAAAGjFIpEJkd0P8aijjgq98t782f30L7zwwtB7+eWX52N29HfZfdwmT55cq7N1kfW6qbzHXXbvzEyn92vtJvfGa8fUqVND77zzzgu9FVZYoVaPHTs2jCnvm8miacKECbV6t912C2NGjx4devvss0/olfedfvrpp8OYP//5z6FX3rc3Oza7FyvzI7sXdHnu+Pjjj4cx06dPD73rr78+9NrO2KH7sjWx4oorht6kSZNCr7zHepkJUlVxP6yqZrk5UFX5OX+5Z2X3Us/Ov8t1lr1vbvoeo6fnfjM9/rVyn8kyOrL7mpd7W7YXZe8BshybNl+3LFssy73IxpXKLLyqiv/uLPcpyzW0VntX9vsu3z984QtfCGOynIhy/8veh2T5eD63WHCVf9fvfve7w5jBgweHXrYHluvl2GOPbfQ4It+EAAAAAAAAWuEiBAAAAAAA0AoXIQAAAAAAgFa4CAEAAAAAALRioQumzsKJDj/88NDbc889Q68Mbxo3blwYc9ttt4WegCL6QrnurMNFS/Z6Z2FaP/rRj0KvDBgsw+2qSggXuSxw67HHHgu9b37zm70xHeiKbD+dOHFirb7gggvCmFVWWSX0Jk+eHHplMLXjdf+XHQMfffTR0MsCMYcMGVKrH3744TBmxowZ8zE7FnVNzgEvuuiiMOaDH/xg6D3//PO1+sILLwxjstDjLKi4Cftfd5R7VBZEnimDqcu6qno/hDqT7cEvvfRS6N111121eujQoWHM9OnTQ2/ChAm1ujxOV5W12l+V67M8X/tnPRY9gwYNqtUHHHBAGFOes1VV/n73jjvuqNXPPvvsfM5u0eWbEAAAAAAAQCtchAAAAAAAAFrhIgQAAAAAANAKFyEAAAAAAIBWLFDB1GWYaiYLI/rMZz4TelmYYCkLtHniiSdCT2gR0B9kIW4CpgH+tWyffPXVV2t1FkCXhVBngZ6dBrjSd5oE/1ZVVd12220dPRd0Wxm+e9ZZZ4UxWVh1uT9lIb5ZSCf9S9N9pny9++vx6fXXXw+9MkQ96z311FNhzDLLLBN65THe+yVYcGSfCy+55JKhN2LEiFq92WabNXrcSy+9FHqnnnpqj2NoxjchAAAAAACAVrgIAQAAAAAAtMJFCAAAAAAAoBUuQgAAAAAAAK3ot8HUTUKoMzNmzAi95557LvTGjBkTemUw0/nnnx/GvPLKKx3NCwCABVOT8GoWPUKn6a+y/WnSpEl9MBN487K9tcl+m32GlIVc27thwZX9/TYJsx8/fnwYs8QS8SPxiy66KPQee+yxHudAM74JAQAAAAAAtMJFCAAAAAAAoBUuQgAAAAAAAK3ot5kQnd5ja9asWaG3++67h94KK6wQeq+99lqtfumllzqaAwAAAADtKDMgyozPqso/HwIWLll22wsvvFCrN9tss96aDv+Cb0IAAAAAAACtcBECAAAAAABohYsQAAAAAABAKxplQnSaz9BfZPPP7hm2oP87e1Nv/K68HpTaXhPWHBnrjt7mGEtfsNfR2+x19AV73cJjQfpdW3f0NsdY+kJPa6LRNyFmzJjRlcn0lblz54b/pk6dGv6bMWNG7T/+ud74/XgNKLW9Jqw5MtYdvc0xlr5gr6O32evoC/Y6+oJ1R29zjKUv9LQmBsxrcOlq7ty51cSJE6tBgwZVAwYM6NrkWPDMmzevmjFjRjVy5MhqscXavZuXdcf/6q11Z83xj6w7eptjLH3BXkdvs9fRF+x19AXrjt7mGEtfaLruGl2EAAAAAAAAeLMEUwMAAAAAAK1wEQIAAAAAAGiFixAAAAAAAEArXIQAAAAAAABa4SIEAAAAAADQChchAAAAAACAVrgIAQAAAAAAtOL/A0KWpNCUcNsPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras import layers\n",
        "# from tensorflow.python.keras.datasets import mnist\n",
        "from tensorflow.python.keras.models import Model\n",
        "\n",
        "def preprocess(array): \n",
        "  \"\"\" \n",
        "  Normalizes the supplied array and reshapes it into the appropriate format. \n",
        "  \"\"\" \n",
        "  \n",
        "  array = array.astype(\"float32\") / 255.0\n",
        "  array = np.reshape(array, (len(array), 28, 28, 1))\n",
        "  return array"
      ],
      "metadata": {
        "id": "-PHfhM4PWfTG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, _), (test_data, _) = mnist.load_data()\n",
        "# Normalize and reshape the data\n",
        "train_data = preprocess(train_data)\n",
        "test_data = preprocess(test_data)"
      ],
      "metadata": {
        "id": "qzwI3AqbTLrA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = layers.Input(shape=(28, 28, 1))\n",
        "# Encoder\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "# Decoder\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
        "# Autoencoder\n",
        "autoencoder = Model(input, x)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78mBpvoATOcY",
        "outputId": "1eb6bdca-4cac-4ed5-db6b-fc30b08d4c05"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 28,353\n",
            "Trainable params: 28,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(\n",
        "  x=train_data,\n",
        "  y=train_data,\n",
        "  epochs=50,\n",
        "  batch_size=128,\n",
        "  shuffle=True,\n",
        "  validation_data=(test_data, test_data),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otqTFy8GTWYH",
        "outputId": "1828632d-7ba8-4e68-ae3e-ca7010806f0f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1374 - val_loss: 0.0729\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0716 - val_loss: 0.0697\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0695 - val_loss: 0.0682\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.0673\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0675 - val_loss: 0.0667\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0669 - val_loss: 0.0662\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0664 - val_loss: 0.0658\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0661 - val_loss: 0.0654\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0657 - val_loss: 0.0652\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0655 - val_loss: 0.0650\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0652 - val_loss: 0.0647\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0650 - val_loss: 0.0645\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0648 - val_loss: 0.0644\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0647 - val_loss: 0.0642\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0645 - val_loss: 0.0640\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0644 - val_loss: 0.0639\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0642 - val_loss: 0.0639\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 4s 7ms/step - loss: 0.0641 - val_loss: 0.0637\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0640 - val_loss: 0.0636\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0639 - val_loss: 0.0635\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0638 - val_loss: 0.0634\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0637 - val_loss: 0.0634\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0637 - val_loss: 0.0633\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0636 - val_loss: 0.0633\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0635 - val_loss: 0.0631\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0635 - val_loss: 0.0632\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0634 - val_loss: 0.0630\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0633 - val_loss: 0.0630\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0633 - val_loss: 0.0629\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0632 - val_loss: 0.0629\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0632 - val_loss: 0.0628\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0631 - val_loss: 0.0628\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0631 - val_loss: 0.0627\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0631 - val_loss: 0.0627\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0630 - val_loss: 0.0627\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0630 - val_loss: 0.0626\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0630 - val_loss: 0.0626\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0629 - val_loss: 0.0625\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0629 - val_loss: 0.0625\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0629 - val_loss: 0.0625\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0628 - val_loss: 0.0625\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0628 - val_loss: 0.0624\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0628 - val_loss: 0.0625\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0627 - val_loss: 0.0624\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0627 - val_loss: 0.0624\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0627 - val_loss: 0.0624\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0627 - val_loss: 0.0623\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0627 - val_loss: 0.0624\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0626 - val_loss: 0.0623\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0626 - val_loss: 0.0623\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f12083c5e80>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(test_data)\n",
        "display(test_data, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JAT7aCYATbDc",
        "outputId": "4ff7edda-4dc0-4dd7-c6c4-84ac3eb43c77"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[[1.42769377e-05],\n",
              "         [8.09128142e-06],\n",
              "         [8.16780599e-08],\n",
              "         ...,\n",
              "         [1.51159028e-07],\n",
              "         [4.18593249e-09],\n",
              "         [3.63055938e-06]],\n",
              "\n",
              "        [[3.99261324e-07],\n",
              "         [1.94084619e-15],\n",
              "         [2.48987241e-15],\n",
              "         ...,\n",
              "         [1.09726228e-17],\n",
              "         [1.37305086e-16],\n",
              "         [1.92134836e-10]],\n",
              "\n",
              "        [[1.13744214e-08],\n",
              "         [2.32717918e-17],\n",
              "         [8.97676046e-19],\n",
              "         ...,\n",
              "         [1.39862510e-18],\n",
              "         [3.01578822e-18],\n",
              "         [1.37765105e-10]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[2.98828446e-08],\n",
              "         [6.51415294e-16],\n",
              "         [2.12608023e-15],\n",
              "         ...,\n",
              "         [8.85305284e-13],\n",
              "         [9.56668338e-13],\n",
              "         [1.76748038e-08]],\n",
              "\n",
              "        [[8.66459970e-09],\n",
              "         [8.74793625e-18],\n",
              "         [1.53295737e-18],\n",
              "         ...,\n",
              "         [2.30591882e-16],\n",
              "         [4.26134335e-16],\n",
              "         [4.66889016e-09]],\n",
              "\n",
              "        [[1.43124225e-06],\n",
              "         [6.41402990e-12],\n",
              "         [9.78888194e-13],\n",
              "         ...,\n",
              "         [1.28099961e-11],\n",
              "         [4.25591810e-12],\n",
              "         [1.50821947e-07]]],\n",
              "\n",
              "\n",
              "       [[[1.42769377e-05],\n",
              "         [8.09128142e-06],\n",
              "         [8.16780599e-08],\n",
              "         ...,\n",
              "         [1.72571760e-07],\n",
              "         [4.45382886e-09],\n",
              "         [3.81939299e-06]],\n",
              "\n",
              "        [[3.99261324e-07],\n",
              "         [1.94084619e-15],\n",
              "         [2.48987241e-15],\n",
              "         ...,\n",
              "         [1.26480209e-17],\n",
              "         [1.47802736e-16],\n",
              "         [2.07853901e-10]],\n",
              "\n",
              "        [[1.13744214e-08],\n",
              "         [2.32717918e-17],\n",
              "         [8.97676046e-19],\n",
              "         ...,\n",
              "         [1.42479658e-18],\n",
              "         [3.05157040e-18],\n",
              "         [1.45013279e-10]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[2.98828446e-08],\n",
              "         [6.51415294e-16],\n",
              "         [2.12607218e-15],\n",
              "         ...,\n",
              "         [2.10616816e-13],\n",
              "         [3.91638151e-14],\n",
              "         [4.52281901e-09]],\n",
              "\n",
              "        [[8.66459970e-09],\n",
              "         [8.74793625e-18],\n",
              "         [1.53295737e-18],\n",
              "         ...,\n",
              "         [1.06755202e-16],\n",
              "         [1.69778900e-16],\n",
              "         [1.29317967e-09]],\n",
              "\n",
              "        [[1.43124225e-06],\n",
              "         [6.41402990e-12],\n",
              "         [9.78888194e-13],\n",
              "         ...,\n",
              "         [2.37141626e-11],\n",
              "         [2.89443925e-12],\n",
              "         [1.29676607e-07]]],\n",
              "\n",
              "\n",
              "       [[[1.42769377e-05],\n",
              "         [8.09128142e-06],\n",
              "         [8.16780599e-08],\n",
              "         ...,\n",
              "         [1.54880524e-07],\n",
              "         [4.82381779e-09],\n",
              "         [4.26967381e-06]],\n",
              "\n",
              "        [[3.99261324e-07],\n",
              "         [1.94084619e-15],\n",
              "         [2.48987241e-15],\n",
              "         ...,\n",
              "         [2.17228299e-17],\n",
              "         [2.01732847e-16],\n",
              "         [2.47371817e-10]],\n",
              "\n",
              "        [[1.13744214e-08],\n",
              "         [2.32717918e-17],\n",
              "         [8.97676046e-19],\n",
              "         ...,\n",
              "         [2.67024055e-18],\n",
              "         [3.41828769e-18],\n",
              "         [1.41478815e-10]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[2.98828446e-08],\n",
              "         [6.51415294e-16],\n",
              "         [2.12607218e-15],\n",
              "         ...,\n",
              "         [7.87459345e-13],\n",
              "         [9.42807030e-13],\n",
              "         [1.80200050e-08]],\n",
              "\n",
              "        [[8.66459970e-09],\n",
              "         [8.74793625e-18],\n",
              "         [1.53295737e-18],\n",
              "         ...,\n",
              "         [2.25810302e-16],\n",
              "         [4.38365120e-16],\n",
              "         [4.77721240e-09]],\n",
              "\n",
              "        [[1.43124225e-06],\n",
              "         [6.41402990e-12],\n",
              "         [9.78888194e-13],\n",
              "         ...,\n",
              "         [1.27433212e-11],\n",
              "         [4.28830756e-12],\n",
              "         [1.50937055e-07]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[1.42767612e-05],\n",
              "         [8.09120502e-06],\n",
              "         [8.16774346e-08],\n",
              "         ...,\n",
              "         [8.13383707e-08],\n",
              "         [4.02574107e-09],\n",
              "         [4.27276973e-06]],\n",
              "\n",
              "        [[3.99260955e-07],\n",
              "         [1.94085360e-15],\n",
              "         [2.48986267e-15],\n",
              "         ...,\n",
              "         [8.65895891e-18],\n",
              "         [1.41954119e-16],\n",
              "         [2.50926335e-10]],\n",
              "\n",
              "        [[1.13743344e-08],\n",
              "         [2.32717918e-17],\n",
              "         [8.97662398e-19],\n",
              "         ...,\n",
              "         [7.98711176e-19],\n",
              "         [3.15433994e-18],\n",
              "         [1.15644883e-10]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[2.98830187e-08],\n",
              "         [6.51407776e-16],\n",
              "         [2.12609674e-15],\n",
              "         ...,\n",
              "         [7.91090392e-13],\n",
              "         [9.40118968e-13],\n",
              "         [1.80150899e-08]],\n",
              "\n",
              "        [[8.66463257e-09],\n",
              "         [8.74796934e-18],\n",
              "         [1.53296316e-18],\n",
              "         ...,\n",
              "         [2.25704370e-16],\n",
              "         [4.37389629e-16],\n",
              "         [4.77446171e-09]],\n",
              "\n",
              "        [[1.43124225e-06],\n",
              "         [6.41406589e-12],\n",
              "         [9.78893724e-13],\n",
              "         ...,\n",
              "         [1.27208331e-11],\n",
              "         [4.28314979e-12],\n",
              "         [1.51034243e-07]]],\n",
              "\n",
              "\n",
              "       [[[1.42767612e-05],\n",
              "         [8.09120502e-06],\n",
              "         [8.16774346e-08],\n",
              "         ...,\n",
              "         [1.51158446e-07],\n",
              "         [4.18591650e-09],\n",
              "         [3.63057006e-06]],\n",
              "\n",
              "        [[3.99260955e-07],\n",
              "         [1.94085360e-15],\n",
              "         [2.48986267e-15],\n",
              "         ...,\n",
              "         [1.09727055e-17],\n",
              "         [1.37304557e-16],\n",
              "         [1.92134836e-10]],\n",
              "\n",
              "        [[1.13743344e-08],\n",
              "         [2.32717918e-17],\n",
              "         [8.97662398e-19],\n",
              "         ...,\n",
              "         [1.39862510e-18],\n",
              "         [3.01577664e-18],\n",
              "         [1.37764841e-10]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[2.98830187e-08],\n",
              "         [6.51407776e-16],\n",
              "         [2.12609674e-15],\n",
              "         ...,\n",
              "         [8.32756227e-13],\n",
              "         [9.42832184e-13],\n",
              "         [1.74759833e-08]],\n",
              "\n",
              "        [[8.66463257e-09],\n",
              "         [8.74796934e-18],\n",
              "         [1.53296316e-18],\n",
              "         ...,\n",
              "         [2.26112004e-16],\n",
              "         [4.25546256e-16],\n",
              "         [4.60744287e-09]],\n",
              "\n",
              "        [[1.43124225e-06],\n",
              "         [6.41406589e-12],\n",
              "         [9.78893724e-13],\n",
              "         ...,\n",
              "         [1.28994150e-11],\n",
              "         [4.24035243e-12],\n",
              "         [1.49700909e-07]]],\n",
              "\n",
              "\n",
              "       [[[1.42767612e-05],\n",
              "         [8.09120502e-06],\n",
              "         [8.16774346e-08],\n",
              "         ...,\n",
              "         [1.37218635e-07],\n",
              "         [4.08059808e-09],\n",
              "         [2.30946421e-06]],\n",
              "\n",
              "        [[3.99260955e-07],\n",
              "         [1.94085360e-15],\n",
              "         [2.48986267e-15],\n",
              "         ...,\n",
              "         [1.61777968e-18],\n",
              "         [9.22603705e-17],\n",
              "         [1.42406073e-10]],\n",
              "\n",
              "        [[1.13743344e-08],\n",
              "         [2.32717918e-17],\n",
              "         [8.97662398e-19],\n",
              "         ...,\n",
              "         [1.96250069e-18],\n",
              "         [1.23303978e-18],\n",
              "         [4.38987041e-11]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[3.08805106e-08],\n",
              "         [6.02915828e-16],\n",
              "         [1.54450560e-15],\n",
              "         ...,\n",
              "         [1.02710917e-12],\n",
              "         [9.12025555e-13],\n",
              "         [1.43480969e-08]],\n",
              "\n",
              "        [[8.26460234e-09],\n",
              "         [8.01595999e-18],\n",
              "         [1.40416876e-18],\n",
              "         ...,\n",
              "         [1.63038887e-16],\n",
              "         [2.73959995e-16],\n",
              "         [4.11542711e-09]],\n",
              "\n",
              "        [[1.37003065e-06],\n",
              "         [6.04340146e-12],\n",
              "         [9.73782036e-13],\n",
              "         ...,\n",
              "         [1.14225816e-11],\n",
              "         [4.35075717e-12],\n",
              "         [1.50142995e-07]]]], dtype=float32)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(array):\n",
        "  \"\"\"\n",
        "  Adds random noise to each image in the supplied array.\n",
        "  \"\"\"\n",
        "\n",
        "  noise_factor = 0.4\n",
        "  noisy_array = array + noise_factor * np.random.normal(\n",
        "    loc=0.0, scale=1.0, size=array.shape\n",
        "  )\n",
        "\n",
        "  return np.clip(noisy_array, 0.0, 1.0)"
      ],
      "metadata": {
        "id": "llwrgyT9TfRc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, _), (test_data, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "train_data = preprocess(train_data)\n",
        "test_data = preprocess(test_data)\n",
        "\n",
        "# Create a copy of the data with added noise\n",
        "noisy_train_data = noise(train_data)\n",
        "noisy_test_data = noise(test_data)\n",
        "\n",
        "# Display the train data and a version of it with added noise\n",
        "display(train_data, noisy_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F6p6T-PxToyR",
        "outputId": "abb3826c-cd14-44d5-dd8a-66306122ed27"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[[0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [1.30516045e-01],\n",
              "         [4.70965011e-01],\n",
              "         [3.45480826e-01]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [7.85518563e-01],\n",
              "         [1.29499711e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [1.54392756e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[3.23221744e-01],\n",
              "         [6.57676002e-02],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [3.04455311e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.94735821e-03],\n",
              "         [4.57756193e-02],\n",
              "         [7.16309720e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [2.80037462e-01]],\n",
              "\n",
              "        [[4.48611808e-01],\n",
              "         [4.39186503e-01],\n",
              "         [2.81605437e-01],\n",
              "         ...,\n",
              "         [9.41639252e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[1.66626425e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [1.03565578e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       [[[0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [3.58003641e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [3.05386174e-02],\n",
              "         [4.92682211e-01]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [5.81658254e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [5.32121064e-01],\n",
              "         [4.96900744e-04]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [6.34439252e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [3.97213012e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.22532166e-01],\n",
              "         [0.00000000e+00],\n",
              "         [1.25700430e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [5.43636346e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[3.57700219e-01],\n",
              "         [2.94705617e-01],\n",
              "         [1.16576066e-01],\n",
              "         ...,\n",
              "         [1.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [2.03569378e-01]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [3.38405132e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [1.70518061e-01]]],\n",
              "\n",
              "\n",
              "       [[[6.36031406e-01],\n",
              "         [7.05064458e-02],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [4.58412726e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [6.40003137e-02],\n",
              "         [4.19783983e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [1.23351082e-01],\n",
              "         [4.42609192e-01],\n",
              "         ...,\n",
              "         [1.97372515e-01],\n",
              "         [0.00000000e+00],\n",
              "         [2.71220789e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[5.14187337e-01],\n",
              "         [0.00000000e+00],\n",
              "         [1.74025231e-01],\n",
              "         ...,\n",
              "         [5.35439999e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[3.12798137e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [3.60994627e-01],\n",
              "         [4.92711872e-02],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [6.46396690e-01],\n",
              "         [1.83055262e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [3.61336810e-02],\n",
              "         [0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [3.86084990e-01],\n",
              "         [4.15488731e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [5.39073256e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [1.46451142e-01],\n",
              "         [0.00000000e+00],\n",
              "         [2.49076418e-01]],\n",
              "\n",
              "        [[7.57127948e-01],\n",
              "         [0.00000000e+00],\n",
              "         [2.75733818e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [1.00084056e-01],\n",
              "         [3.10434315e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[9.24098650e-03],\n",
              "         [0.00000000e+00],\n",
              "         [1.34227134e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [8.28634982e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [4.36987597e-01],\n",
              "         [5.54268417e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[5.46284695e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [4.83740657e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       [[[1.12126652e-01],\n",
              "         [9.06771078e-01],\n",
              "         [2.81686930e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [1.98221404e-02]],\n",
              "\n",
              "        [[2.80693053e-01],\n",
              "         [7.60421433e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [1.68058086e-02],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [2.43034393e-01],\n",
              "         [9.32474939e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.64901800e-01],\n",
              "         [5.51154071e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [1.39415842e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [2.95751324e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [3.71586575e-01]],\n",
              "\n",
              "        [[2.35200623e-02],\n",
              "         [0.00000000e+00],\n",
              "         [4.36747209e-02],\n",
              "         ...,\n",
              "         [3.03826998e-01],\n",
              "         [9.95041865e-02],\n",
              "         [3.17016444e-01]]],\n",
              "\n",
              "\n",
              "       [[[0.00000000e+00],\n",
              "         [5.52778515e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [3.03105767e-01],\n",
              "         [0.00000000e+00],\n",
              "         [1.65893864e-01]],\n",
              "\n",
              "        [[3.76067228e-01],\n",
              "         [5.03957999e-01],\n",
              "         [3.48459571e-03],\n",
              "         ...,\n",
              "         [3.24115366e-02],\n",
              "         [0.00000000e+00],\n",
              "         [1.81594676e-01]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [2.84700456e-01],\n",
              "         [4.08860559e-02],\n",
              "         ...,\n",
              "         [2.24653233e-01],\n",
              "         [0.00000000e+00],\n",
              "         [6.85143930e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[4.49962316e-01],\n",
              "         [2.08951511e-01],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [5.83406075e-02],\n",
              "         [4.72147562e-01],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [2.64818960e-01],\n",
              "         ...,\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00]],\n",
              "\n",
              "        [[3.66987983e-01],\n",
              "         [0.00000000e+00],\n",
              "         [0.00000000e+00],\n",
              "         ...,\n",
              "         [3.36409239e-01],\n",
              "         [0.00000000e+00],\n",
              "         [7.47373202e-02]]]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(\n",
        "  x=noisy_train_data,\n",
        "  y=train_data,\n",
        "  epochs=100,\n",
        "  batch_size=128,\n",
        "  shuffle=True,\n",
        "  validation_data=(noisy_test_data, test_data),\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTgGxLz9TweB",
        "outputId": "432a4bae-b94a-44b2-95e3-9b4115fbb9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0999 - val_loss: 0.0930\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0925 - val_loss: 0.0910\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0910 - val_loss: 0.0899\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0900 - val_loss: 0.0891\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0893 - val_loss: 0.0885\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0887 - val_loss: 0.0880\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0883 - val_loss: 0.0877\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0879 - val_loss: 0.0871\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0876 - val_loss: 0.0869\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0873 - val_loss: 0.0867\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0870 - val_loss: 0.0864\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0868 - val_loss: 0.0864\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0866 - val_loss: 0.0861\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0865 - val_loss: 0.0859\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0863 - val_loss: 0.0858\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0862 - val_loss: 0.0857\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0861 - val_loss: 0.0855\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0859 - val_loss: 0.0855\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0859 - val_loss: 0.0858\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0858 - val_loss: 0.0854\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0857 - val_loss: 0.0853\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0856 - val_loss: 0.0856\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0855 - val_loss: 0.0851\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0855 - val_loss: 0.0851\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0854 - val_loss: 0.0852\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0853 - val_loss: 0.0850\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0853 - val_loss: 0.0851\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0852 - val_loss: 0.0849\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0852 - val_loss: 0.0851\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0851 - val_loss: 0.0848\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0851 - val_loss: 0.0847\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0850 - val_loss: 0.0849\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0850 - val_loss: 0.0849\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0850 - val_loss: 0.0847\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0849 - val_loss: 0.0848\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0849 - val_loss: 0.0846\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0849 - val_loss: 0.0847\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0849 - val_loss: 0.0846\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0848 - val_loss: 0.0845\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0848 - val_loss: 0.0846\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0848 - val_loss: 0.0846\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0847 - val_loss: 0.0847\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0847 - val_loss: 0.0845\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0847 - val_loss: 0.0845\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0847 - val_loss: 0.0846\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0847 - val_loss: 0.0844\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0846 - val_loss: 0.0847\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0846 - val_loss: 0.0844\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0846 - val_loss: 0.0845\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0846 - val_loss: 0.0844\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0846 - val_loss: 0.0843\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0845 - val_loss: 0.0845\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0845 - val_loss: 0.0848\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0845 - val_loss: 0.0843\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0845 - val_loss: 0.0844\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0845 - val_loss: 0.0843\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0845 - val_loss: 0.0843\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0843\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0843\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0842\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0843 - val_loss: 0.0842\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0843\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0842\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0843 - val_loss: 0.0842\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0842\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0842\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0842 - val_loss: 0.0842\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0842\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0841\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0842\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 4s 7ms/step - loss: 0.0842 - val_loss: 0.0841\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0841\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0841\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0841\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0842 - val_loss: 0.0841\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0842 - val_loss: 0.0841\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0841 - val_loss: 0.0840\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0841\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0843\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0840\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0841 - val_loss: 0.0841\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0841\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0840\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0841 - val_loss: 0.0841\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0843\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0842\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0841 - val_loss: 0.0840\n",
            "Epoch 99/100\n",
            "379/469 [=======================>......] - ETA: 0s - loss: 0.0840"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(noisy_test_data)\n",
        "display(noisy_test_data, predictions)"
      ],
      "metadata": {
        "id": "E7jGfgAXT1Sn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}